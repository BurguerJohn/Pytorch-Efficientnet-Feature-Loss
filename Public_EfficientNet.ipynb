{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Public EfficientNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh8sCV518fN7"
      },
      "source": [
        "Installing Torch 1.10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iG-kx6rMu3xE"
      },
      "source": [
        "!pip3 install torch==1.10.0+cu113 torchvision==0.11.1+cu113 torchaudio===0.10.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9MfPIKs8mDq"
      },
      "source": [
        "The function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do4SD5p1u8Z3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms\n",
        "\n",
        "class EfficLoss(torch.nn.Module):\n",
        "    def __init__(self, rescale):\n",
        "        super(EfficLoss, self).__init__()\n",
        "        self.features  = models.efficientnet_b7(pretrained=True).eval().features\n",
        "        if rescale:\n",
        "          self.normalize = transforms.Compose([transforms.Resize(224), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\n",
        "        else:\n",
        "          self.normalize = transforms.Compose([transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\n",
        "        \n",
        "        self.l1  = nn.L1Loss()\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, X, Y):\n",
        "        X = self.normalize(X)\n",
        "        Y = self.normalize(Y)\n",
        "\n",
        "        indices = [1, 2, 3, 4, 5]\n",
        "        weight = [1 / 16, 1 / 8, 1/ 4, 1, 1]\n",
        "        \n",
        "        k = 0\n",
        "        loss = 0\n",
        "        \n",
        "        for i in range(indices[-1] + 1):\n",
        "          X = self.features[i](X)\n",
        "          Y = self.features[i](Y)\n",
        "          if i in indices:\n",
        "            curr = self.l1(X, Y) * weight[k]\n",
        "            #curr = (X - Y).abs().mean() * weight[k]\n",
        "            loss += curr\n",
        "            k += 1\n",
        "        return loss"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOOiybvW8diL"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys8b3xOj1PH5"
      },
      "source": [
        "img1 = torch.rand((1, 3, 256, 256))\n",
        "img2 = torch.rand((1, 3, 256, 256))\n",
        "\n",
        "Eff = EfficLoss(True)\n",
        "\n",
        "loss = Eff(img1, img2)\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}